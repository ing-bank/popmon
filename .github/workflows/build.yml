name: build

on:
  push:
    branches: [ master, develop ]
  pull_request:

jobs:
  test:
    strategy:
      matrix:
        os: [ubuntu-latest]
        python: [3.7, 3.8, 3.9]
    runs-on: ${{ matrix.os }}

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install -r requirements-test.txt
    - name: Lint with pre-commit
      run: |
        make lint
    - name: Test with pytest
      run: |
        pytest -m "not spark"
        
  test_spark:
    strategy:
      matrix:
        os: [ubuntu-latest]
        python: [3.7]
    runs-on: ${{ matrix.os }}
      
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install -r requirements-test.txt
    - name: Install Spark
      env:
        BUILD_DIR: "/home/runner/work/" #${{ github.workspace }}
        JAVA_HOME: "/usr/lib/jvm/java-8-openjdk-amd64"
        SPARK_VERSION: "2.4.7"
        HADOOP_VERSION: "2.7"
        SPARK_HOME: "/home/runner/work/spark/" #${{ github.workspace }}/spark/
        SPARK_LOCAL_IP: "localhost"
      run: |
        sudo apt-get update
        sudo apt-get -y install openjdk-8-jdk
        curl https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz --output ${BUILD_DIR}/spark.tgz
        tar -xvzf ${BUILD_DIR}/spark.tgz && mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} ${SPARK_HOME}
        pip install pytest-spark>=0.6.0 pyarrow>=0.8.0 pyspark==2.4.7
    - name: Test with pytest (spark-specific)
      env:
        SPARK_LOCAL_IP: "localhost"
      run: |
        pytest -m spark

  examples:
    runs-on: ubuntu-latest
    needs: 
    - test
    - test_spark
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.7
        uses: actions/setup-python@v1
        with:
          python-version: 3.7
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
      - name: Build examples
        run: |
          cd examples
          python synthetic_data.py
          python flight_delays.py
      - uses: actions/upload-artifact@v2
        with:
          name: synthetic-report
          path: examples/test_data_report.html
          if-no-files-found: error
      - uses: actions/upload-artifact@v2
        with:
          name: flight-delays-report
          path: examples/flight_delays_report.html
          if-no-files-found: error
